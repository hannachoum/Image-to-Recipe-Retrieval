{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import tqdm\n",
    "from transformers import CLIPTextConfig, CLIPTextModel\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device,\"device\")\n",
    "\n",
    "\n",
    "\n",
    "#Note : launch the bert etc with the new mapping csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_bert_path = \"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Summaries/export_summary_Bert.csv\"\n",
    "summary_bert = pd.read_csv(summary_bert_path)\n",
    "\n",
    "\n",
    "summary_bert_ingredients_path=\"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Summaries/export_summary_bert_with_ingredients.csv\"\n",
    "summary_bert_ingredients=pd.read_csv(summary_bert_ingredients_path)\n",
    "\n",
    "\n",
    "images_path=\"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/\"\n",
    "\n",
    "data_dir = \"ComputerVision_Data\"\n",
    "images_dir = \"Food Images/Food Images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a clean dataset with the same number of images and text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "number of sumary recipe  13463\n",
      "number of images  13582\n",
      "after adding some filtering we have number of images  13463\n",
      "13463\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "recipe = summary_bert[\"Summary\"].tolist()\n",
    "print(type(recipe))\n",
    "print(\"number of sumary recipe \",len(recipe))\n",
    "\n",
    "#print(recipe[:2])\n",
    "\n",
    "images = os.listdir(os.path.join(data_dir, images_dir))\n",
    "#print(type(images))\n",
    "print(\"number of images \",len(images))\n",
    "\n",
    "liste=summary_bert[\"Image_Name\"].tolist()\n",
    "liste = [item + \".jpg\" for item in liste]\n",
    "\n",
    "#print(liste[:5])\n",
    "\n",
    "\n",
    "images = [image for image in images if os.path.basename(image) in liste ]  \n",
    "print(\"after adding some filtering we have number of images \",len(images))\n",
    "\n",
    "images = [image[:-4] for image in images]\n",
    "\n",
    "\n",
    "#Create a CSV with only the images and the recipe who fit together\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_path = 'ComputerVision_Data/Food Ingredients and Recipe Dataset with Image Name Mapping.csv'\n",
    "csv_path2= 'ComputerVision_Data/Mapping.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Filter the DataFrame based on the \"Image_Name\" column\n",
    "df_filtered = df[df['Image_Name'].isin(images)]\n",
    "\n",
    "# Save the filtered DataFrame back to the CSV file\n",
    "df_filtered.to_csv(csv_path2, index=False)\n",
    "\n",
    "print(len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/miso-butter-roast-chicken-acorn-squash-panzanella.jpg', '/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/crispy-salt-and-pepper-potatoes-dan-kluger.jpg', '/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/thanksgiving-mac-and-cheese-erick-williams.jpg', '/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/italian-sausage-and-bread-stuffing-240559.jpg', '/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/newtons-law-apple-bourbon-cocktail.jpg']\n",
      "['Pat chicken dry with paper towels, season all over with 2 tsp. salt, and tie legs together with kitchen twine. Let sit at room temperature 1 hour.\\nMeanwhile, halve squash and scoop out seeds. Run a vegetable peeler along ridges of squash halves to remove skin. Cut each half into ½\"-thick wedges; arrange on a rimmed baking sheet.\\nCombine sage, rosemary, and 6 Tbsp. melted butter in a large bowl; pour half of mixture over squash on baking sheet. Sprinkle squash with allspice, red pepper flakes, and ½ tsp. salt and season with black pepper; toss to coat.\\nAdd bread, apples, oil, and ¼ tsp. salt to remaining herb butter in bowl; season with black pepper and toss to combine. Set aside.\\nPlace onion and vinegar in a small bowl; season with salt and toss to coat. Let sit, tossing occasionally, until ready to serve.\\nPlace a rack in middle and lower third of oven; preheat to 425°F. Mix miso and 3 Tbsp. room-temperature butter in a small bowl until smooth. Pat chicken dry with paper towels, then rub or brush all over with miso butter. Place chicken in a large cast-iron skillet and roast on middle rack until an instant-read thermometer inserted into the thickest part of breast registers 155°F, 50–60 minutes. (Temperature will climb to 165°F while chicken rests.) Let chicken rest in skillet at least 5 minutes, then transfer to a plate; reserve skillet.\\nMeanwhile, roast squash on lower rack until mostly tender, about 25 minutes. Remove from oven and scatter reserved bread mixture over, spreading into as even a layer as you can manage. Return to oven and roast until bread is golden brown and crisp and apples are tender, about 15 minutes. Remove from oven, drain pickled onions, and toss to combine. Transfer to a serving dish.\\nUsing your fingers, mash flour and butter in a small bowl to combine.\\nSet reserved skillet with chicken drippings over medium heat. You should have about ¼ cup, but a little over or under is all good. (If you have significantly more, drain off and set excess aside.) Add wine and cook, stirring often and scraping up any browned bits with a wooden spoon, until bits are loosened and wine is reduced by about half (you should be able to smell the wine), about 2 minutes. Add butter mixture; cook, stirring often, until a smooth paste forms, about 2 minutes. Add broth and any reserved drippings and cook, stirring constantly, until combined and thickened, 6–8 minutes. Remove from heat and stir in miso. Taste and season with salt and black pepper.\\nServe chicken with gravy and squash panzanella alongside.', 'Preheat oven to 400°F and line a rimmed baking sheet with parchment. In a large bowl, whisk the egg whites until foamy (there shouldn’t be any liquid whites in the bowl). Add the potatoes and toss until they’re well coated with the egg whites, then transfer to a strainer or colander and let the excess whites drain. Season the potatoes with the salt, pepper, and herbs. Scatter the potatoes on the baking sheet (make sure they’re not touching) and roast until the potatoes are very crispy and tender when poked with a knife, 15 to 20 minutes (depending on the size of the potatoes).\\nTransfer to a bowl and serve.', 'Place a rack in middle of oven; preheat to 400°. Bring evaporated milk and whole milk to a bare simmer in a large saucepan over medium heat. Whisk in garlic powder, onion powder, paprika, pepper, and 1 tsp. salt. Working in batches, whisk in three fourths of the cheddar, then all of the cream cheese.\\nMeanwhile, bring a large pot of generously salted water to a boil (it should have a little less salt than seawater). Cook macaroni, stirring occasionally, until very al dente, about 4 minutes. Drain in a colander.\\nAdd macaroni to cheese sauce in pan and mix until well coated. Evenly spread out half of macaroni mixture in a 13x9\" baking dish. Sprinkle half of remaining cheddar evenly over. Layer remaining macaroni mixture on top and sprinkle with remaining cheddar. Bake until all of the cheese is melted, about 10 minutes. Let cool slightly before serving.', \"Preheat oven to 350°F with rack in middle. Generously butter baking dish.\\nPut bread in 2 shallow baking pans and bake, switching position of pans halfway through baking, until just dried out, about 10 minutes.\\nHeat 1 tablespoon oil in a 12-inch heavy skillet over medium-high heat until it shimmers, then cook half of sausage, stirring and breaking it into small pieces, until golden brown, about 6 minutes. Transfer with a slotted spoon to a large bowl. Brown remaining sausage in remaining tablespoon oil, transferring to bowl.\\nPour off fat from skillet and wipe clean. Heat butter over medium heat until foam subsides, then cook onions, celery, garlic, and ½ teaspoon each of salt and pepper, stirring occasionally, until golden, 12 to 15 minutes. Add vegetables and bread to sausage.\\nWhisk together eggs, ½ cup cream, turkey stock, cheese, and parsley, then stir into stuffing and cool completely, about 30 minutes. Reserve 5 cups stuffing to stuff turkey and spoon remainder into baking dish, then drizzle with remaining ¼ cup cream. Cover stuffing and chill.\\nAbout 1 hour before stuffed turkey is finished roasting, bring dish of stuffing to room temperature. When turkey is done, increase oven temperature to 425°F and bake stuffing, covered tightly with foil, until hot throughout, about 20 minutes. Remove foil and bake until top is golden and crisp, about 15 minutes more.\\nCooks' Note: Bread can be toasted 3 days ahead and kept (once cool) in a sealed bag at room temperature. Stuffing can be prepared (but not baked) 4 hours before roasting turkey. If baking stuffing at the same time as potatoes, put stuffing in upper third of oven and potatoes in bottom third (allow extra time).\", 'Stir together brown sugar and hot water in a cocktail shaker to dissolve. Let cool, then add bourbon, lemon juice, and apple butter and fill with ice. Shake until well chilled, about 15 seconds. Strain into an ice-filled rocks glass. Garnish with orange twist and cinnamon.']\n",
      "['[\\'1 (3½–4-lb.) whole chicken\\', \\'2¾ tsp. kosher salt, divided, plus more\\', \\'2 small acorn squash (about 3 lb. total)\\', \\'2 Tbsp. finely chopped sage\\', \\'1 Tbsp. finely chopped rosemary\\', \\'6 Tbsp. unsalted butter, melted, plus 3 Tbsp. room temperature\\', \\'¼ tsp. ground allspice\\', \\'Pinch of crushed red pepper flakes\\', \\'Freshly ground black pepper\\', \\'⅓ loaf good-quality sturdy white bread, torn into 1\" pieces (about 2½ cups)\\', \\'2 medium apples (such as Gala or Pink Lady; about 14 oz. total), cored, cut into 1\" pieces\\', \\'2 Tbsp. extra-virgin olive oil\\', \\'½ small red onion, thinly sliced\\', \\'3 Tbsp. apple cider vinegar\\', \\'1 Tbsp. white miso\\', \\'¼ cup all-purpose flour\\', \\'2 Tbsp. unsalted butter, room temperature\\', \\'¼ cup dry white wine\\', \\'2 cups unsalted chicken broth\\', \\'2 tsp. white miso\\', \\'Kosher salt, freshly ground pepper\\']', \"['2 large egg whites', '1 pound new potatoes (about 1 inch in diameter)', '2 teaspoons kosher salt', '¾ teaspoon finely ground black pepper', '1 teaspoon finely chopped rosemary', '1 teaspoon finely chopped thyme', '1 teaspoon finely chopped parsley']\", \"['1 cup evaporated milk', '1 cup whole milk', '1 tsp. garlic powder', '1 tsp. onion powder', '1 tsp. smoked paprika', '½ tsp. freshly ground black pepper', '1 tsp. kosher salt, plus more', '2 lb. extra-sharp cheddar, coarsely grated', '4 oz. full-fat cream cheese', '1 lb. elbow macaroni']\", \"['1 (¾- to 1-pound) round Italian loaf, cut into 1-inch cubes (8 cups)', '2 tablespoons olive oil, divided', '2 pounds sweet Italian sausage, casings removed, divided', '1 stick unsalted butter, cut into pieces', '3 medium onions, chopped', '4 large celery ribs, chopped', '5 garlic cloves, minced', '4 large eggs, lightly beaten', '¾ cup heavy cream, divided', '½ cup turkey giblet stock or reduced-sodium chicken broth', '1 cup grated Parmigiano-Reggiano (2 ounces)', '½ cup coarsely chopped flat-leaf parsley', '4-qt shallow ceramic or glass baking dish']\", \"['1 teaspoon dark brown sugar', '1 teaspoon hot water', '1 ½ oz. bourbon', '½ oz. fresh lemon juice', '2 teaspoons apple butter (storebought or homemade)', 'Garnish: orange twist and freshly grated or ground cinnamon']\"]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Mapping.csv\"\n",
    "dataset = pd.read_csv(dataset)\n",
    "\n",
    "Instructions=dataset[\"Instructions\"].tolist()\n",
    "Ingredients=dataset[\"Ingredients\"].tolist()\n",
    "images=dataset[\"Image_Name\"]\n",
    "\n",
    "path_folder_image= \"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Food Images/Food Images/\"\n",
    "images = [os.path.join(path_folder_image, image) for image in images]\n",
    "images = [item + \".jpg\" for item in images]\n",
    "\n",
    "print(images[:5])\n",
    "print(Instructions[:5])\n",
    "print(Ingredients[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data processing on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whole chicken kosher salt divided plus moresmall acorn squash about total fin', ' large egg whitespound new potatoes aboutinch in diameterteaspoons kosher sal', ' cup evaporated milkcup whole milk garlic powder onion powder smoked paprika ', 'to pound round Italian loaf cut into inch cubescupstablespoons olive oil divi', ' teaspoon dark brown sugarteaspoon hot water oz bourbonoz fresh lemon juicete']\n"
     ]
    }
   ],
   "source": [
    "to_supress = string.punctuation + \"—\" + \"–\" + \"()\"\n",
    "\n",
    "for i in range(len(Ingredients)): \n",
    "    temp = Ingredients[i].translate(str.maketrans(\"\", \"\",to_supress))\n",
    "    temp= ''.join([char for char in temp if not char.isdigit()])\n",
    "    Ingredients[i]=temp.replace(\"Tbsp\", \"\").replace(\"½\", \"\").replace(\"¾\", \"\").replace(\"lb\", \"\").replace(\"tsp\", \"\").replace(\"⅓\", \"\").replace(\"  \", \"\").replace(\"¼\", \"\")\n",
    "    \n",
    "    #A remplacer quand on aura trouvé la bonne manière de rallonger le context length\n",
    "    if len(Ingredients)>77:\n",
    "        Ingredients[i]=Ingredients[i][:77]\n",
    "\n",
    "print(Ingredients[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/PIL/Image.py:3251\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3251\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# add your own code to track the training progress.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[0;32m---> 59\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader :\n\u001b[1;32m     60\u001b[0m       optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     62\u001b[0m       images,texts \u001b[38;5;241m=\u001b[39m batch \n",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[82], line 29\u001b[0m, in \u001b[0;36mimage_title_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 29\u001b[0m     image \u001b[38;5;241m=\u001b[39m preprocess(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# Image from PIL module\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle[idx]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image,title\n",
      "File \u001b[0;32m~/Computer-Vision/.venv/lib64/python3.9/site-packages/PIL/Image.py:3253\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3253\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[1;32m   3254\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Latest Update : 18 July 2022, 09:55 GMT+7\n",
    "\n",
    "# TO ADD :\n",
    "# Gradient Checkpointing\n",
    "# Filter out bias from weight decay\n",
    "# Decaying learning rate with cosine schedule\n",
    "# Half-precision Adam statistics\n",
    "# Half-precision stochastically rounded text encoder weights were used\n",
    "\n",
    "#BATCH_SIZE must larger than 1\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "BATCH_SIZE=8\n",
    "EPOCH=2\n",
    "optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "class image_title_dataset(Dataset):\n",
    "    def __init__(self, list_image_path,list_txt):\n",
    "\n",
    "        self.image_path = list_image_path\n",
    "        self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = preprocess(Image.open(self.image_path[idx])) # Image from PIL module\n",
    "        title = self.title[idx]\n",
    "        return image,title\n",
    "    \n",
    "\n",
    "\n",
    "# use your own data\n",
    "list_image_path = images \n",
    "list_txt = Ingredients\n",
    "dataset = image_title_dataset(list_image_path,list_txt)\n",
    "train_dataloader = DataLoader(dataset,batch_size = BATCH_SIZE) #Define your own dataloader\n",
    "\n",
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "\n",
    "if device == \"cpu\":\n",
    "  model.float()\n",
    "else :\n",
    "  clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# add your own code to track the training progress.\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "  for batch in train_dataloader :\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      images,texts = batch \n",
    "      print(\"image shape\", images.shape)\n",
    "      print(\"text shape\",texts.shape)\n",
    "    \n",
    "      images= images.to(device)\n",
    "      texts = texts.to(device)\n",
    "    \n",
    "      logits_per_image, logits_per_text = model(images, texts)\n",
    "\n",
    "      ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "\n",
    "      total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "      total_loss.backward()\n",
    "      if device == \"cpu\":\n",
    "         optimizer.step()\n",
    "      else : \n",
    "        convert_models_to_fp32(model)\n",
    "        optimizer.step()\n",
    "        clip.model.convert_weights(model)\n",
    "\n",
    "\n",
    "torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': total_loss,\n",
    "        }, f\"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Checkpoints/checkpoint_number_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
