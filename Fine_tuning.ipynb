{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import clip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device,\"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_bert_path = \"/users/eleves-b/2022/hanna.mergui/Computer-Vision/ComputerVision_Data/Summaries/export_summary_Bert.csv\"\n",
    "summary_bert = pd.read_csv(summary_bert_path)\n",
    "\n",
    "data_dir = \"ComputerVision_Data\"\n",
    "images_dir = \"Food Images/Food Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sumary recipe  13463\n",
      "number of images  3486\n"
     ]
    }
   ],
   "source": [
    "recipe = summary_bert[\"Summary\"]\n",
    "print(\"number of sumary recipe \",len(recipe))\n",
    "\n",
    "images = os.listdir(os.path.join(data_dir, images_dir))\n",
    "print(\"number of images \",len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RN50', 'ViT-B/32']\n"
     ]
    }
   ],
   "source": [
    "models = clip.available_models()\n",
    "print(models)\n",
    "model, preprocess = clip.load('RN50', device,jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n#Tensor creation \\n\\n# Creation of a tensor for the text \\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\n#print(device,\"device\")\\ntext_tensor = torch.zeros(len(summary_bert), context_length, dtype=torch.long)\\nlabels = []\\nfor i, row in enumerate(summary_bert.iterrows()):\\n    summary = row[1][\"Summary\"]\\n    if i==0: \\n        print(summary)\\n        summary = summary[:context_length]  # Truncate the text if it\\'s too long\\n    text_tensor[i] = clip.tokenize([summary],truncate=True).to(device)  # Access row data using integer indices\\n    labels.append(row[1][\"Image_Name\"])  # Access row data using integer indices\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "#Tensor creation \n",
    "\n",
    "# Creation of a tensor for the text \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(device,\"device\")\n",
    "text_tensor = torch.zeros(len(summary_bert), context_length, dtype=torch.long)\n",
    "labels = []\n",
    "for i, row in enumerate(summary_bert.iterrows()):\n",
    "    summary = row[1][\"Summary\"]\n",
    "    if i==0: \n",
    "        print(summary)\n",
    "        summary = summary[:context_length]  # Truncate the text if it's too long\n",
    "    text_tensor[i] = clip.tokenize([summary],truncate=True).to(device)  # Access row data using integer indices\n",
    "    labels.append(row[1][\"Image_Name\"])  # Access row data using integer indices\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#torch.save(text_tensor, \"text_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tensor = torch.load(\"text_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_inputs=[]\n",
    "\n",
    "for im in images:\n",
    "    im_path = os.path.join(data_dir, images_dir, im)\n",
    "    images_inputs.append(preprocess(Image.open(im_path)))\n",
    "images_inputs_tensor = torch.tensor(np.stack(images_inputs)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_tensor shape torch.Size([13463, 77])\n",
      "images_inputs_tensor shape  torch.Size([3486, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(\"text_tensor shape\", text_tensor.shape)\n",
    "print(\"images_inputs_tensor shape \", images_inputs_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each image, we want to loop over each element of the tensor and calculate the cosine similarity. \n",
    "#At the end , we want to keep the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.3574  0.608   0.03482]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Demo\n",
    "\n",
    "image = preprocess(Image.open(\"ComputerVision_Data/Food Images/Food Images/-bloody-mary-tomato-toast-with-celery-and-horseradish-56389813.jpg\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_recipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
