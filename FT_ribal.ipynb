{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/recipe/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CONTEXT_LENGTH = 77\n",
    "SAMPLE_SIZE = None\n",
    "TRAIN_PROP = 0.7\n",
    "VAL_PROP = 0.2\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 5e-6\n",
    "\n",
    "# Params same as paper\n",
    "BETAS = (0.9,0.98)\n",
    "EPS = 1e-6\n",
    "WEIGHT_DECAY = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
     ]
    }
   ],
   "source": [
    "models = clip.available_models()\n",
    "print(models)\n",
    "model, preprocess = clip.load('RN50', device, jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP(\n",
      "  (visual): ModifiedResNet(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (attnpool): AttentionPool2d(\n",
      "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): Sequential(\n",
      "      (0): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (token_embedding): Embedding(49408, 512)\n",
      "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextImg_Dataset(Dataset):\n",
    "    def __init__(self, data_dir, images_dir, images, titles, augmented_text=False, augmented_image=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.images_dir = images_dir\n",
    "        self.images_paths = images\n",
    "        self.titles = titles\n",
    "        assert (len(titles)==len(images))\n",
    "        self.augmented_text = augmented_text\n",
    "        self.augmented_image = augmented_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "    \n",
    "    def transform_img(self, img):\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "            transforms.RandomRotation(30),  # Randomly rotate the image by up to 30 degrees\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly change brightness, contrast, saturation, and hue\n",
    "        ])\n",
    "        return transform(img)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        txt = self.titles[index]\n",
    "        img_path = self.images_paths[index]\n",
    "        text_tokens = clip.tokenize(txt, context_length=CONTEXT_LENGTH, truncate=True).squeeze().to(device) # torch.Size([77])\n",
    "        # print(type(text_tokens), text_tokens.shape)\n",
    "        path = os.path.join(self.data_dir, self.images_dir, img_path)\n",
    "        img = Image.open(path)\n",
    "        if self.augmented_image:\n",
    "            img = self.transform_img(img)\n",
    "        image = preprocess(img).to(device) # torch.Size([3, 224, 224])\n",
    "        # print(type(image), image.shape)\n",
    "        return text_tokens, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_bert_path = \"data/Summaries/Summary_Bert_65.csv\"\n",
    "summary_bert_path = \"data/Summaries/export_summary_bert_with_ingredients.csv\"\n",
    "data_dir = \"data\"\n",
    "images_dir = \"Food Images/Food Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.read_csv(summary_bert_path)\n",
    "liste_images = summary_df[\"Image_Name\"].tolist()\n",
    "liste_textes = summary_df[\"summary_with_ingredients\"].tolist()\n",
    "if SAMPLE_SIZE != None:\n",
    "    liste_images=liste_images[:SAMPLE_SIZE]\n",
    "    liste_textes=liste_textes[:SAMPLE_SIZE]\n",
    "liste_images = [image + \".jpg\" for image in liste_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('miso-butter-roast-chicken-acorn-squash-panzanella.jpg',\n",
       " 'Roast chicken in a large cast-iron skillet until an instant-read thermometer inserted into the thickest part of breast registers 155°F, 50–60 minutes. Meanwhile, roast squash on lower rack until mostly tender, about 25 minutes.Whole chicken')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_images[0], liste_textes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n"
     ]
    }
   ],
   "source": [
    "assert(len(liste_textes) == len(liste_images))\n",
    "length = len(liste_images)\n",
    "print(length)\n",
    "train_size = int(length*TRAIN_PROP)\n",
    "val_size = int(length*VAL_PROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextImg_Dataset(data_dir, images_dir, liste_images[:train_size], liste_textes[:train_size])\n",
    "train_dataset_augmented = TextImg_Dataset(data_dir, images_dir, liste_images[:train_size], liste_textes[:train_size], augmented_text=True, augmented_image=True)\n",
    "val_dataset = TextImg_Dataset(data_dir, images_dir, liste_images[train_size:train_size+val_size], liste_textes[train_size:train_size+val_size])\n",
    "test_dataset = TextImg_Dataset(data_dir, images_dir, liste_images[train_size+val_size:], liste_textes[train_size+val_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset_augmented, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_dl = DataLoader(test_dataset, batch_size=500, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " [tensor([[49406,  1983,   320,  ...,     0,     0,     0],\n",
       "          [49406,  4741,   753,  ...,     0,     0,     0],\n",
       "          [49406, 12919,   518,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [49406,   622,   516,  ...,     0,     0,     0],\n",
       "          [49406,  6803,  5066,  ...,     0,     0,     0],\n",
       "          [49406,   679,  4403,  ...,     0,     0,     0]], device='cuda:0',\n",
       "         dtype=torch.int32),\n",
       "  tensor([[[[-1.3981, -1.3981, -1.3981,  ...,  1.6822,  1.6822,  1.6822],\n",
       "            [-1.3981, -1.3981, -1.3981,  ...,  1.6822,  1.6822,  1.6822],\n",
       "            [-1.3981, -1.3981, -1.3981,  ...,  1.6822,  1.6822,  1.6822],\n",
       "            ...,\n",
       "            [ 1.4778,  1.4778,  1.4778,  ..., -1.3981, -1.3981, -1.3981],\n",
       "            [ 1.4778,  1.4778,  1.4778,  ..., -1.3981, -1.3981, -1.3981],\n",
       "            [ 1.4778,  1.4778,  1.4778,  ..., -1.3981, -1.3981, -1.3981]],\n",
       "  \n",
       "           [[-1.3469, -1.3469, -1.3469,  ...,  1.8198,  1.8198,  1.8198],\n",
       "            [-1.3469, -1.3469, -1.3469,  ...,  1.8198,  1.8198,  1.8198],\n",
       "            [-1.3469, -1.3469, -1.3469,  ...,  1.8198,  1.8198,  1.8198],\n",
       "            ...,\n",
       "            [ 1.6096,  1.6096,  1.6096,  ..., -1.3469, -1.3469, -1.3469],\n",
       "            [ 1.6096,  1.6096,  1.6096,  ..., -1.3469, -1.3469, -1.3469],\n",
       "            [ 1.6096,  1.6096,  1.6096,  ..., -1.3469, -1.3469, -1.3469]],\n",
       "  \n",
       "           [[-1.0963, -1.0963, -1.0963,  ...,  1.9184,  1.9184,  1.9184],\n",
       "            [-1.0963, -1.0963, -1.0963,  ...,  1.9184,  1.9184,  1.9184],\n",
       "            [-1.0963, -1.0963, -1.0963,  ...,  1.9184,  1.9184,  1.9184],\n",
       "            ...,\n",
       "            [ 1.7193,  1.7193,  1.7193,  ..., -1.0963, -1.0963, -1.0963],\n",
       "            [ 1.7193,  1.7193,  1.7193,  ..., -1.0963, -1.0963, -1.0963],\n",
       "            [ 1.7193,  1.7193,  1.7193,  ..., -1.0963, -1.0963, -1.0963]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.9893, -0.9602, -0.8872,  ..., -1.7485, -1.7485, -1.7485],\n",
       "            [-0.9602, -1.0039, -1.0185,  ..., -1.7485, -1.7485, -1.7485],\n",
       "            [-0.9602, -0.9893, -1.0331,  ..., -1.7485, -1.7485, -1.7485],\n",
       "            ...,\n",
       "            [-1.7485, -1.7485, -1.7485,  ..., -0.4784, -0.3178, -0.2448],\n",
       "            [-1.7485, -1.7485, -1.7485,  ..., -0.3616, -0.2302, -0.1426],\n",
       "            [-1.7485, -1.7485, -1.7485,  ..., -0.1134, -0.1280, -0.1426]],\n",
       "  \n",
       "           [[-1.0317, -1.0017, -0.9417,  ..., -1.7071, -1.7071, -1.7071],\n",
       "            [-0.9867, -1.0317, -1.0767,  ..., -1.7071, -1.7071, -1.7071],\n",
       "            [-0.9867, -1.0167, -1.0767,  ..., -1.7071, -1.7071, -1.7071],\n",
       "            ...,\n",
       "            [-1.7071, -1.7071, -1.7071,  ..., -0.4164, -0.2813, -0.2513],\n",
       "            [-1.7071, -1.7071, -1.7071,  ..., -0.3114, -0.2063, -0.1463],\n",
       "            [-1.7071, -1.7071, -1.7071,  ..., -0.1012, -0.1463, -0.1463]],\n",
       "  \n",
       "           [[-1.0252, -0.9967, -0.9256,  ..., -1.4376, -1.4376, -1.4376],\n",
       "            [-1.0252, -1.0394, -1.0394,  ..., -1.4376, -1.4376, -1.4376],\n",
       "            [-1.0394, -1.0252, -1.0252,  ..., -1.4376, -1.4376, -1.4376],\n",
       "            ...,\n",
       "            [-1.4376, -1.4376, -1.4376,  ..., -0.9114, -0.7550, -0.6697],\n",
       "            [-1.4376, -1.4376, -1.4376,  ..., -0.7977, -0.6697, -0.5701],\n",
       "            [-1.4376, -1.4376, -1.4376,  ..., -0.5559, -0.5559, -0.5701]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.7923, -1.7923, -1.7923,  ..., -1.6609, -1.1791, -0.0550],\n",
       "            [-1.7923, -1.7923, -1.7923,  ..., -0.9018, -0.3616,  0.9376],\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  0.2515,  0.6019,  1.4778],\n",
       "            ...,\n",
       "            [ 1.3172,  0.7041, -0.4784,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 1.4194,  1.5800,  0.9230,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 0.6895,  1.3756,  1.4632,  ..., -1.7923, -1.7923, -1.7923]],\n",
       "  \n",
       "           [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.4669, -0.4014],\n",
       "            [-1.7521, -1.7521, -1.7521,  ..., -1.2718, -0.7166,  0.6341],\n",
       "            [-1.7521, -1.7521, -1.7521,  ..., -0.1313,  0.2740,  1.2044],\n",
       "            ...,\n",
       "            [ 0.3040, -0.0712, -0.9267,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [ 0.0939,  0.3940, -0.0262,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [-0.7616,  0.0488,  0.3340,  ..., -1.7521, -1.7521, -1.7521]],\n",
       "  \n",
       "           [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.1958, -0.1009],\n",
       "            [-1.4802, -1.4802, -1.4802,  ..., -0.9541, -0.3995,  1.0225],\n",
       "            [-1.4802, -1.4802, -1.4802,  ...,  0.2973,  0.7239,  1.7193],\n",
       "            ...,\n",
       "            [ 0.9941,  0.6386, -0.3000,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [ 0.8377,  1.2785,  0.9088,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [ 0.0555,  0.9656,  1.3496,  ..., -1.4802, -1.4802, -1.4802]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-1.3543, -1.3543, -1.3543,  ...,  1.5070,  1.5508,  1.7114],\n",
       "            [-1.3543, -1.3543, -1.3543,  ...,  1.5508,  1.5946,  1.7114],\n",
       "            [-1.3543, -1.3543, -1.3543,  ...,  1.3464,  1.6676,  1.5946],\n",
       "            ...,\n",
       "            [ 1.7406,  1.7406,  1.7406,  ..., -1.3543, -1.3543, -1.3543],\n",
       "            [ 1.7406,  1.7406,  1.7406,  ..., -1.3543, -1.3543, -1.3543],\n",
       "            [ 1.7406,  1.7406,  1.7406,  ..., -1.3543, -1.3543, -1.3543]],\n",
       "  \n",
       "           [[-1.3019, -1.3019, -1.3019,  ...,  1.4145,  1.5196,  1.7147],\n",
       "            [-1.3019, -1.3019, -1.3019,  ...,  1.5196,  1.6397,  1.7897],\n",
       "            [-1.3019, -1.3019, -1.3019,  ...,  1.3695,  1.7747,  1.7597],\n",
       "            ...,\n",
       "            [ 1.8798,  1.8798,  1.8798,  ..., -1.3019, -1.3019, -1.3019],\n",
       "            [ 1.8798,  1.8798,  1.8798,  ..., -1.3019, -1.3019, -1.3019],\n",
       "            [ 1.8798,  1.8798,  1.8798,  ..., -1.3019, -1.3019, -1.3019]],\n",
       "  \n",
       "           [[-1.0536, -1.0536, -1.0536,  ...,  1.2643,  1.5060,  1.6909],\n",
       "            [-1.0536, -1.0536, -1.0536,  ...,  1.4633,  1.6766,  1.8046],\n",
       "            [-1.0536, -1.0536, -1.0536,  ...,  1.4065,  1.8331,  1.8188],\n",
       "            ...,\n",
       "            [ 1.9610,  1.9610,  1.9610,  ..., -1.0536, -1.0536, -1.0536],\n",
       "            [ 1.9610,  1.9610,  1.9610,  ..., -1.0536, -1.0536, -1.0536],\n",
       "            [ 1.9610,  1.9610,  1.9610,  ..., -1.0536, -1.0536, -1.0536]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.9960,  0.9960,  1.0252,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 0.9960,  0.9960,  1.0106,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 0.9960,  1.0252,  1.0544,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            ...,\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  0.8792,  1.0836,  1.1128],\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  0.9230,  1.0398,  1.2150],\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  0.9960,  0.9668,  1.2442]],\n",
       "  \n",
       "           [[ 1.1294,  1.1144,  1.1294,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [ 1.1294,  1.1144,  1.1294,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [ 1.1294,  1.1594,  1.1894,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            ...,\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  0.9493,  1.1144,  1.0844],\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  0.9643,  1.0243,  1.1894],\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  0.9943,  0.9493,  1.2645]],\n",
       "  \n",
       "           [[-0.2857, -0.2857, -0.2715,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [-0.2857, -0.2857, -0.2715,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [-0.2857, -0.2431, -0.2289,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            ...,\n",
       "            [-1.4802, -1.4802, -1.4802,  ..., -0.8688, -0.6270, -0.5275],\n",
       "            [-1.4802, -1.4802, -1.4802,  ..., -0.8545, -0.7123, -0.4706],\n",
       "            [-1.4802, -1.4802, -1.4802,  ..., -0.7977, -0.8119, -0.4564]]],\n",
       "  \n",
       "  \n",
       "          [[[ 1.2296,  1.2004,  1.1566,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 1.1566,  1.2004,  1.1858,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            [ 1.1274,  1.1128,  0.8792,  ..., -1.7923, -1.7923, -1.7923],\n",
       "            ...,\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  1.1420,  1.1566,  1.1566],\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  1.1420,  1.1566,  1.1566],\n",
       "            [-1.7923, -1.7923, -1.7923,  ...,  1.1566,  1.1566,  1.1566]],\n",
       "  \n",
       "           [[ 1.3695,  1.3395,  1.2795,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [ 1.2795,  1.3395,  1.3095,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            [ 1.2645,  1.2495,  1.0093,  ..., -1.7521, -1.7521, -1.7521],\n",
       "            ...,\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  1.2495,  1.2645,  1.2645],\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  1.2495,  1.2645,  1.2645],\n",
       "            [-1.7521, -1.7521, -1.7521,  ...,  1.2645,  1.2645,  1.2645]],\n",
       "  \n",
       "           [[ 1.4491,  1.4207,  1.3780,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [ 1.3780,  1.4207,  1.4065,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            [ 1.3496,  1.3354,  1.1078,  ..., -1.4802, -1.4802, -1.4802],\n",
       "            ...,\n",
       "            [-1.4802, -1.4802, -1.4802,  ...,  1.3922,  1.4065,  1.4065],\n",
       "            [-1.4802, -1.4802, -1.4802,  ...,  1.3922,  1.4065,  1.4065],\n",
       "            [-1.4802, -1.4802, -1.4802,  ...,  1.4065,  1.4065,  1.4065]]]],\n",
       "         device='cuda:0')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl), next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(text_embeddings, image_embeddings):\n",
    "    logits = (text_embeddings @ image_embeddings.T)\n",
    "    images_similarity = image_embeddings @ image_embeddings.T\n",
    "    texts_similarity = text_embeddings @ text_embeddings.T\n",
    "    targets = F.softmax(\n",
    "        (images_similarity + texts_similarity) / 2, dim=-1\n",
    "    )\n",
    "    texts_loss = cross_entropy(logits, targets, reduction='none')\n",
    "    images_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
    "    loss =  (images_loss + texts_loss) / 2.0 # shape: (batch_size)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def cross_entropy(preds, targets, reduction='none'):\n",
    "    log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "    loss = (-targets * log_softmax(preds)).sum(1)\n",
    "    if reduction == \"none\":\n",
    "        return loss\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "    \n",
    "def get_accuracy(text_features, image_features):\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "    ground_truth = torch.arange(similarity.shape[0]).to(device)\n",
    "    max_indices = torch.argmax(similarity, dim=1)\n",
    "    return torch.mean((max_indices == ground_truth).float()).item() *100\n",
    "\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.float()\n",
    "        print(type(p.data), p.data)\n",
    "        p.grad.data = p.grad.data.float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE,betas=BETAS,eps=EPS,weight_decay=WEIGHT_DECAY)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:10<00:00,  1.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 14/14 [00:09<00:00,  1.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s]\n",
      "100%|██████████| 14/14 [00:09<00:00,  1.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory data/checkpoints does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         val_accuracies\u001b[38;5;241m.\u001b[39mappend(val_acc\u001b[38;5;241m/\u001b[39mb_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m         val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/checkpoints/trained_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m/Data/recipe/venv/lib64/python3.9/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    625\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Data/recipe/venv/lib64/python3.9/site-packages/torch/serialization.py:502\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Data/recipe/venv/lib64/python3.9/site-packages/torch/serialization.py:473\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory data/checkpoints does not exist."
     ]
    }
   ],
   "source": [
    "clip.model.convert_weights(model)\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_dl): \n",
    "        optimizer.zero_grad()\n",
    "        text, img = batch\n",
    "        # print(text.shape, img.shape)\n",
    "        text_features = model.encode_text(text)\n",
    "        image_features = model.encode_image(img)\n",
    "        loss = compute_loss(text_features, image_features)\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # VALIDATION LOOP\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        for b_idx, batch in enumerate(tqdm(val_dl)): \n",
    "            text, img = batch\n",
    "            # print(text.shape, img.shape)\n",
    "            text_features = model.encode_text(text)\n",
    "            image_features = model.encode_image(img)\n",
    "            loss = compute_loss(text_features, image_features)\n",
    "            val_loss+=loss.item()\n",
    "            val_acc += get_accuracy(text_features, image_features)\n",
    "        val_accuracies.append(val_acc/b_idx+1)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "torch.save(model.state_dict(), \"data/checkpoints/trained_model.pt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([54.931640625,\n",
       "  46.724609375,\n",
       "  41.876953125,\n",
       "  36.494140625,\n",
       "  31.0263671875,\n",
       "  23.572265625,\n",
       "  17.1455078125,\n",
       "  12.544921875,\n",
       "  8.808837890625],\n",
       " [14.71875,\n",
       "  14.4921875,\n",
       "  14.236328125,\n",
       "  14.173828125,\n",
       "  14.13671875,\n",
       "  14.130859375,\n",
       "  14.23046875,\n",
       "  14.60546875,\n",
       "  14.662109375],\n",
       " [12.658654113610586,\n",
       "  13.700320780277252,\n",
       "  15.903846383094788,\n",
       "  14.100961595773697,\n",
       "  17.98717971642812,\n",
       "  16.70512826244036,\n",
       "  17.346154113610584,\n",
       "  17.58653865257899,\n",
       "  16.544871985912323])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1098, 1221)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dl), train_size+val_size, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 77]) torch.Size([123, 3, 224, 224])\n",
      "Accuracy: 36.59 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for b in test_dl:\n",
    "        text, img = b\n",
    "        print(text.shape, img.shape)\n",
    "        text_features = model.encode_text(text)\n",
    "        image_features = model.encode_image(img)\n",
    "\n",
    "        accuracy = get_accuracy(text_features, image_features)\n",
    "\n",
    "        # clip_score = torch.matmul(image_features, text_features.T)\n",
    "        print(f'Accuracy: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
